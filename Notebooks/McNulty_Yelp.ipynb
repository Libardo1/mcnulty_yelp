{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standard libraries\n",
    "import re, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Machine learning modules\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#Text processing libraries\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords ##Note you'll need to download NLTK and corpuses\n",
    "from spacy.en import English ##Note you'll need to install Spacy and download its dependencies\n",
    "parser = English()\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom function to clean the text before sending it into the vectorizer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    text = re.sub('[^a-zA-Z ]','',text)\n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "#     text = str(TextBlob(text).correct())\n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's get our data. If you don't have the pickle its in the dropbox\n",
    "with open(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/review_business_df.pkl\", 'rb') as picklefile: \n",
    "    review_business_df = pickle.load(picklefile)\n",
    "\n",
    "sample_df = review_business_df.sample(10000,random_state=1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that I've only extract 10,000 sample reviews. This is just to manage its tracktability. Lemmatizing takes a really long time. Indirectly, 10,000 reviews is also big enough relative to the 3,000 features (refer to discussion on vectorizer below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_df = sample_df.iloc[:,0:2]\n",
    "short_df.text= short_df.text.apply(cleanText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bag of Words Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define your vectorizers. There's no need for tfidfvectorizer since we'll use tfidftransformer below\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3),min_df=3, max_features=3000,tokenizer=tokenizeText)\n",
    "# tfvectorizer = TfidfVectorizer(ngram_range=(1,3),min_df = 3,max_features=3000,tokenizer=tokenizeText,sublinear_tf=True)\n",
    "##This transforms our count vectors into tfidf vectors\n",
    "tffeature = TfidfTransformer().fit_transform(countfeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take note of the assumptions made in the vectorizer specifications. There are two kinds of vectorizers initialized: count and tfidf. I've limited both to consider only (1 to 3) n-grams that appear in at least 3 documents. I've also limited the feature set into the top 3,000 n-grams that appear the most often in the reviews. You can edit any of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Gets the count of each word in each sentence\n",
    "countfeature = vectorizer.fit_transform(short_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Turns count/tfidf matrices into dataframes\n",
    "countfeaturedf = pd.DataFrame(countfeature.A, columns=vectorizer.get_feature_names())\n",
    "tffeaturedf = pd.DataFrame(tffeature.A, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Concat Y and X. Note that I'll be concatinating and transforming both the count and tfidf data frames\n",
    "new_df_count = pd.concat((short_df,countfeaturedf),axis=1)\n",
    "new_df_tf = pd.concat((short_df,tffeaturedf),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 3002 entries, text to zucchini\n",
      "dtypes: int64(3001), object(1)\n",
      "memory usage: 229.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 3002 entries, text to zucchini\n",
      "dtypes: float64(3000), int64(1), object(1)\n",
      "memory usage: 229.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_df_count.info())\n",
    "print(new_df_tf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Do not run until the above cells are run or else you'll replace your pickle files with empty files.\n",
    "import pickle\n",
    "new_df_count.to_pickle('C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/new_df_count.pkl')\n",
    "new_df_tf.to_pickle('C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/new_df_tf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "new_df_count = pd.read_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/new_df_count.pkl\")\n",
    "new_df_tf = pd.read_pickle('C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/new_df_tf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Transforming other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Turn star rating from integers to text\n",
    "def string(x):\n",
    "    if x == 5:\n",
    "        return \"five\"\n",
    "    elif x == 4:\n",
    "        return 'four'\n",
    "    elif x == 3:\n",
    "        return 'three'\n",
    "    elif x == 2:\n",
    "        return 'two'\n",
    "    elif x == 1:\n",
    "        return 'one'\n",
    "\n",
    "##Apply this if you want to collapse the 5-star ratings by removing 3-star reviews and combining 1 & 2 stars \n",
    "##and 4 & 5 ratings\n",
    "\n",
    "def collapse(x):\n",
    "    if x == 'four' or x == 'five':\n",
    "        return 'four/five'\n",
    "    elif x == 'one' or x == 'two':\n",
    "        return 'one/two'\n",
    "    elif x == 'three':\n",
    "        return 'three'\n",
    "\n",
    "# Run if you want to delete 3-stars\n",
    "# collapse_df = collapse_df[new_df['stars_x'] != 'three']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df_count['stars_x'] = new_df_count['stars_x'].apply(string)\n",
    "new_df_tf['stars_x'] = new_df_tf['stars_x'].apply(string)\n",
    "##Just assigning to new dataframes, in case we want to refer to the un-collapsed dataframes\n",
    "collapse_df_count = new_df_count.copy()\n",
    "collapse_df_tf = new_df_tf.copy()\n",
    "collapse_df_count.stars_x = new_df_count.stars_x.apply(collapse)\n",
    "collapse_df_tf.stars_x = new_df_tf.stars_x.apply(collapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "four/five    0.6553\n",
       "one/two      0.1953\n",
       "three        0.1494\n",
       "Name: stars_x, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_df_count.stars_x.value_counts()/collapse_df_count.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Adds sentiment as a feature. Note that I added 1 because some algorithms won't accept negative sentiment scores\n",
    "##Sentiment scores is based on TextBlob where it goes from -1.0 to 1.0 (negative to positive)\n",
    "##Change the reference DF if you want to go back to using the 5-star categories\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "collapse_df_count['senti'] = collapse_df_count['text'].apply(lambda x: TextBlob(x).sentiment[0] + 1)\n",
    "collapse_df_tf['senti'] = collapse_df_tf['text'].apply(lambda x: TextBlob(x).sentiment[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##To be used for vectorization of non-Yelp data (or outside of those sampled)\n",
    "pickle.dump(np.array(collapse_df_count.columns)[2:-1], open(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/vocab.pkl\",\"wb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Split into train and test at 75/25\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df_count.values,test_size = 0.25,random_state=1)\n",
    "\n",
    "##Split X & Y\n",
    "X_train = train[:,2:]\n",
    "Y_train = train[:,1]\n",
    "X_test = test[:,2:]\n",
    "Y_test = test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.0 Neural network trial (can be ingnored and skip to 2.1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Integrize\n",
    "def destring(x):\n",
    "    if x == 'four/five':\n",
    "        return 5\n",
    "    elif x == 'three':\n",
    "        return 3\n",
    "    elif x == 'one/two':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_df_count = collapse_df_count.copy()\n",
    "nn_df_tf = collapse_df_tf.copy()\n",
    "nn_df_count.stars_x = collapse_df_count.stars_x.apply(destring)\n",
    "nn_df_tf.stars_x = collapse_df_tf.stars_x.apply(destring)\n",
    "##Split into train and test at 75/25\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df_count.values,test_size = 0.25,random_state=1)\n",
    "\n",
    "##Split X & Y\n",
    "X_train = train[:,2:]\n",
    "Y_train = train[:,1]\n",
    "X_test = test[:,2:]\n",
    "Y_test = test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
       "      f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Tanh`: units=100, frozen=False, name='hidden0'>,\n",
       "      layers=[<sknn.nn.Layer `Tanh`: units=100, frozen=False, name='hidden0'>, <sknn.nn.Layer `Softmax`: units=3, frozen=False, name='output'>],\n",
       "      learning_momentum=0.9, learning_rate=0.001, learning_rule='sgd',\n",
       "      loss_type=None, n_iter=25, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: units=3, frozen=False, name='output'>,\n",
       "      parameters=None, random_state=None, regularize=None, valid_set=None,\n",
       "      valid_size=0.0, verbose=None, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units=100),\n",
    "        Layer(\"Softmax\",units=3)],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25)\n",
    "nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2500, 3)]\n",
      "NN:  0.51353088\n",
      "[[1493   43  110]\n",
      " [  82  327   69]\n",
      " [ 176   79  121]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.85      0.91      0.88      1646\n",
      "    one/two       0.73      0.68      0.71       478\n",
      "      three       0.40      0.32      0.36       376\n",
      "\n",
      "avg / total       0.76      0.78      0.77      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_Y_pred = nn.predict(X_test)\n",
    "print(\"NN: \",np.mean(nn_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,nn_Y_pred))\n",
    "print(classification_report(Y_test,nn_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2500, 3)]\n",
      "NN:  0.54405728\n",
      "[[1577   55   14]\n",
      " [  97  368   13]\n",
      " [ 220  116   40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.83      0.96      0.89      1646\n",
      "    one/two       0.68      0.77      0.72       478\n",
      "      three       0.60      0.11      0.18       376\n",
      "\n",
      "avg / total       0.77      0.79      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Split into train and test at 75/25\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df_tf.values,test_size = 0.25,random_state=1)\n",
    "\n",
    "##Split X & Y\n",
    "X_train = train[:,2:]\n",
    "Y_train = train[:,1]\n",
    "X_test = test[:,2:]\n",
    "Y_test = test[:,1]\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units=100),\n",
    "        Layer(\"Softmax\",units=3)],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25)\n",
    "nn.fit(X_train, Y_train)\n",
    "\n",
    "nn_Y_pred = nn.predict(X_test)\n",
    "print(\"NN: \",np.mean(nn_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,nn_Y_pred))\n",
    "print(classification_report(Y_test,nn_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Relatively quick models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.75, class_prior=None, fit_prior=True)\n",
      "NB Accuracy:  0.766\n",
      "[[1442   65  139]\n",
      " [  71  326   81]\n",
      " [ 156   73  147]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.86      0.88      0.87      1646\n",
      "    one/two       0.70      0.68      0.69       478\n",
      "      three       0.40      0.39      0.40       376\n",
      "\n",
      "avg / total       0.76      0.77      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_param_grid = [{'alpha':[0.01,0.1,0.25,0.5,0.75,1.0]}]\n",
    "nb = GridSearchCV(MultinomialNB(),nb_param_grid,cv=5,n_jobs=-1)\n",
    "nb.fit(X_train,Y_train)\n",
    "nb_Y_pred = nb.predict(X_test)\n",
    "print(nb.best_estimator_)\n",
    "print(\"NB Accuracy: \",np.mean(nb_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,nb_Y_pred))\n",
    "print(classification_report(Y_test,nb_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Logistc Accuracy:  0.7872\n",
      "[[1571   29   46]\n",
      " [ 118  319   41]\n",
      " [ 224   74   78]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.82      0.95      0.88      1646\n",
      "    one/two       0.76      0.67      0.71       478\n",
      "      three       0.47      0.21      0.29       376\n",
      "\n",
      "avg / total       0.76      0.79      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_param_grid = [{'C':[0.01,0.1,1,10], 'penalty':['l1','l2'],'class_weight':[None,'balanced']}]\n",
    "log = GridSearchCV(LogisticRegression(),log_param_grid,cv=5,n_jobs=-1)\n",
    "log.fit(X_train,Y_train)\n",
    "log_Y_pred = log.predict(X_test)\n",
    "print(log.best_estimator_)\n",
    "print(\"Logistc Accuracy: \",np.mean(log_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,log_Y_pred))\n",
    "print(classification_report(Y_test,log_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear Accuracy:  0.7888\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "[[1572   33   41]\n",
      " [ 114  329   35]\n",
      " [ 223   82   71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.82      0.96      0.88      1646\n",
      "    one/two       0.74      0.69      0.71       478\n",
      "      three       0.48      0.19      0.27       376\n",
      "\n",
      "avg / total       0.76      0.79      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svcl_param_grid = [{'C':[0.01,0.1,1,10,100], 'loss':['hinge','squared_hinge'],'class_weight':[None,'balanced']}]\n",
    "svcl = GridSearchCV(LinearSVC(),svcl_param_grid,cv=5,n_jobs=-1)\n",
    "svcl.fit(X_train,Y_train)\n",
    "svcl_Y_pred = svcl.predict(X_test)\n",
    "print(\"SVC Linear Accuracy: \",np.mean(svcl_Y_pred == np.array(Y_test)))\n",
    "print(svcl.best_estimator_)\n",
    "print(confusion_matrix(Y_test,svcl_Y_pred))\n",
    "print(classification_report(Y_test,svcl_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Relatively slow models \n",
    "Grid search will not be performed on the models below, takes too long.\n",
    "(Warning: do not run unless you are using a high-powered cloud computer, for real.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform')\n",
      "KNN Accuracy:  0.652\n",
      "[[1457  165   24]\n",
      " [ 306  164    8]\n",
      " [ 287   80    9]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.71      0.89      0.79      1646\n",
      "    one/two       0.40      0.34      0.37       478\n",
      "      three       0.22      0.02      0.04       376\n",
      "\n",
      "avg / total       0.58      0.65      0.60      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train,Y_train)\n",
    "knn_Y_pred = knn.predict(X_test)\n",
    "print(\"KNN Accuracy: \",np.mean(knn_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,knn_Y_pred))\n",
    "print(classification_report(Y_test,knn_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF Accuracy:  0.6828\n",
      "[[1638    8    0]\n",
      " [ 409   69    0]\n",
      " [ 371    5    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.68      1.00      0.81      1646\n",
      "    one/two       0.84      0.14      0.25       478\n",
      "      three       0.00      0.00      0.00       376\n",
      "\n",
      "avg / total       0.61      0.68      0.58      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Non-linear SVC\n",
    "from sklearn.svm import SVC\n",
    "svcrbf = SVC(kernel='rbf')\n",
    "svcrbf.fit(X_train,Y_train)\n",
    "svcrbf_Y_pred = svcrbf.predict(X_test)\n",
    "print(\"SVC RBF Accuracy: \",np.mean(svcrbf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,svcrbf_Y_pred))\n",
    "print(classification_report(Y_test,svcrbf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Accuracy:  0.7416\n",
      "[[1569   46   31]\n",
      " [ 202  254   22]\n",
      " [ 278   67   31]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.77      0.95      0.85      1646\n",
      "    one/two       0.69      0.53      0.60       478\n",
      "      three       0.37      0.08      0.13       376\n",
      "\n",
      "avg / total       0.69      0.74      0.69      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,Y_train)\n",
    "rf_Y_pred = rf.predict(X_test)\n",
    "print(\"Random Forests Accuracy: \",np.mean(rf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,rf_Y_pred))\n",
    "print(classification_report(Y_test,rf_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Pickle models\n",
    "joblib.dump(nb,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_nb.pkl')\n",
    "joblib.dump(log,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_log.pkl')\n",
    "joblib.dump(svcl,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_svcl.pkl')\n",
    "joblib.dump(knn,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_knn.pkl')\n",
    "joblib.dump(svcrbf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_svcrbf.pkl')\n",
    "joblib.dump(rf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_rf.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using tfidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split into train and test at 75/25\n",
    "##Note the change to collase_df_tf dataframe below\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df_tf.values,test_size = 0.25,random_state=1)\n",
    "\n",
    "##Split X & Y\n",
    "X_train = train[:,2:]\n",
    "Y_train = train[:,1]\n",
    "X_test = test[:,2:]\n",
    "Y_test = test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Relatively fast models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "NB Accuracy:  0.7632\n",
      "[[1618   20    8]\n",
      " [ 194  262   22]\n",
      " [ 304   44   28]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.76      0.98      0.86      1646\n",
      "    one/two       0.80      0.55      0.65       478\n",
      "      three       0.48      0.07      0.13       376\n",
      "\n",
      "avg / total       0.73      0.76      0.71      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_param_grid = [{'alpha':[0.01,0.1,0.25,0.5,0.75,1.0]}]\n",
    "nb_tf = GridSearchCV(MultinomialNB(),nb_param_grid,cv=5,n_jobs=-1)\n",
    "nb_tf.fit(X_train,Y_train)\n",
    "nb_tf_Y_pred = nb_tf.predict(X_test)\n",
    "print(nb_tf.best_estimator_)\n",
    "print(\"NB Accuracy: \",np.mean(nb_tf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,nb_tf_Y_pred))\n",
    "print(classification_report(Y_test,nb_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Logistc Accuracy:  0.7968\n",
      "[[1602   33   11]\n",
      " [ 114  343   21]\n",
      " [ 251   78   47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.81      0.97      0.89      1646\n",
      "    one/two       0.76      0.72      0.74       478\n",
      "      three       0.59      0.12      0.21       376\n",
      "\n",
      "avg / total       0.77      0.80      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_param_grid = [{'C':[0.01,0.1,1,10], 'penalty':['l1','l2'],'class_weight':[None,'balanced']}]\n",
    "log_tf = GridSearchCV(LogisticRegression(),log_param_grid,cv=5,n_jobs=-1)\n",
    "log_tf.fit(X_train,Y_train)\n",
    "log_tf_Y_pred = log_tf.predict(X_test)\n",
    "print(log_tf.best_estimator_)\n",
    "print(\"Logistc Accuracy: \",np.mean(log_tf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,log_tf_Y_pred))\n",
    "print(classification_report(Y_test,log_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear Accuracy:  0.7948\n",
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n",
      "[[1588   49    9]\n",
      " [ 101  356   21]\n",
      " [ 232  101   43]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.83      0.96      0.89      1646\n",
      "    one/two       0.70      0.74      0.72       478\n",
      "      three       0.59      0.11      0.19       376\n",
      "\n",
      "avg / total       0.77      0.79      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svcl_param_grid = [{'C':[0.01,0.1,1,10,100], 'loss':['hinge','squared_hinge'],'class_weight':[None,'balanced']}]\n",
    "svcl_tf = GridSearchCV(LinearSVC(),svcl_param_grid,cv=5,n_jobs=-1)\n",
    "svcl_tf.fit(X_train,Y_train)\n",
    "svcl_tf_Y_pred = svcl_tf.predict(X_test)\n",
    "print(\"SVC Linear Accuracy: \",np.mean(svcl_tf_Y_pred == np.array(Y_test)))\n",
    "print(svcl_tf.best_estimator_)\n",
    "print(confusion_matrix(Y_test,svcl_tf_Y_pred))\n",
    "print(classification_report(Y_test,svcl_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Relatively slow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy:  0.2868\n",
      "[[ 254 1392    0]\n",
      " [  14  463    1]\n",
      " [  27  349    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.86      0.15      0.26      1646\n",
      "    one/two       0.21      0.97      0.35       478\n",
      "      three       0.00      0.00      0.00       376\n",
      "\n",
      "avg / total       0.61      0.29      0.24      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_tf = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_tf.fit(X_train,Y_train)\n",
    "knn_tf_Y_pred = knn_tf.predict(X_test)\n",
    "print(\"KNN Accuracy: \",np.mean(knn_tf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,knn_tf_Y_pred))\n",
    "print(classification_report(Y_test,knn_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF Accuracy:  0.6584\n",
      "[[1646    0    0]\n",
      " [ 478    0    0]\n",
      " [ 376    0    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.66      1.00      0.79      1646\n",
      "    one/two       0.00      0.00      0.00       478\n",
      "      three       0.00      0.00      0.00       376\n",
      "\n",
      "avg / total       0.43      0.66      0.52      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Non-linear SVC\n",
    "from sklearn.svm import SVC\n",
    "svcrbf_tf = SVC(kernel='rbf')\n",
    "svcrbf_tf.fit(X_train,Y_train)\n",
    "svcrbf_tf_Y_pred = svcrbf_tf.predict(X_test)\n",
    "print(\"SVC RBF Accuracy: \",np.mean(svcrbf_tf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,svcrbf_tf_Y_pred))\n",
    "print(classification_report(Y_test,svcrbf_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Accuracy:  0.7552\n",
      "[[1581   46   19]\n",
      " [ 178  283   17]\n",
      " [ 280   72   24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.78      0.96      0.86      1646\n",
      "    one/two       0.71      0.59      0.64       478\n",
      "      three       0.40      0.06      0.11       376\n",
      "\n",
      "avg / total       0.71      0.76      0.70      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_tf = RandomForestClassifier()\n",
    "rf_tf.fit(X_train,Y_train)\n",
    "rf_tf_Y_pred = rf_tf.predict(X_test)\n",
    "print(\"Random Forests Accuracy: \",np.mean(rf_tf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,rf_tf_Y_pred))\n",
    "print(classification_report(Y_test,rf_tf_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Pickle models\n",
    "joblib.dump(nb_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_nb_tf.pkl')\n",
    "joblib.dump(log_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_log_tf.pkl')\n",
    "joblib.dump(svcl_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_svcl.pkl')\n",
    "joblib.dump(knn_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_knn_tf.pkl')\n",
    "joblib.dump(svcrbf_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_svcrbf.pkl')\n",
    "joblib.dump(rf_tf,'C:/Users/Administrator/Documents/Github/mcnulty_yelp/model/model_rf.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Applying model to tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Load vocab list from previously run vectorizer so we can extract the same words that were used in our model\n",
    "vocab_list = pickle.load( open( \"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/vocab.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Download data\n",
    "tweet_df = pd.read_pickle('C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweets_clean.pkl')\n",
    "tweet_df = tweet_df.drop_duplicates('text').reset_index(drop=True)\n",
    "\n",
    "##Extract the same feature set we have in Yelp from tweets\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1,3),min_df=3, max_features=3000,tokenizer=tokenizeText,vocabulary=vocab_list)\n",
    "tweet_sparse_matrix = vectorizer2.transform(tweet_df.text)\n",
    "tweet_sparse_matrix_tf = TfidfTransformer().fit_transform(tweet_sparse_matrix)\n",
    "tweet_count_df = pd.DataFrame(tweet_sparse_matrix.A, columns=vocab_list)\n",
    "tweet_tf_df = pd.DataFrame(tweet_sparse_matrix_tf.A, columns=vocab_list)\n",
    "\n",
    "##Pickle pickle\n",
    "tweet_count_df.to_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_count_df.pkl\")\n",
    "tweet_count_df = pd.read_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_count_df.pkl\")\n",
    "\n",
    "tweet_tf_df.to_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_tf_df.pkl\")\n",
    "tweet_tf_df = pd.read_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_tf_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Combine and add sentiment score\n",
    "tweet_count_df = pd.concat((tweet_df,tweet_count_df),axis=1)\n",
    "tweet_count_df['senti'] = tweet_df.text.apply(lambda x: TextBlob(x).sentiment[0] + 1)\n",
    "\n",
    "tweet_tf_df = pd.concat((tweet_df,tweet_tf_df),axis=1)\n",
    "tweet_tf_df['senti'] = tweet_df.text.apply(lambda x: TextBlob(x).sentiment[0] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Apply best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get feature set\n",
    "X_tweet = tweet_tf_df.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Best model was Tfidf Linear SVC\n",
    "## Predicts categories and probabilities\n",
    "tweet_pred = log_tf.predict(X_tweet)\n",
    "tweet_pred_prob = log_tf.predict_proba(X_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Combine into one dataframe\n",
    "tweet_df['pred'] = tweet_pred\n",
    "tweet_prob_df = pd.DataFrame(tweet_pred_prob,columns = ['prob_4/5','prob_1/2','prob_3'])\n",
    "tweet_df = pd.concat((tweet_df,tweet_prob_df),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Pickle, pickle\n",
    "tweet_df.to_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_df_pred.pkl\")\n",
    "tweet_df_pred = pd.read_pickle(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/data/tweet_df_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Save as CSV\n",
    "tweet_df_pred.to_csv(\"C:/Users/Administrator/Documents/Github/mcnulty_yelp/datatweet_df_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
