{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Spell checker from Peter Norvig. Not perfect, but works.\n",
    "import re, collections\n",
    "\n",
    "def words(text): return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    "\n",
    "NWORDS = train(words(open('C:/Users/kenndanielso/Documents/Github/mcnulty_yelp/data/big.txt').read()))\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def edits1(word):\n",
    "   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "   deletes    = [a + b[1:] for a, b in splits if b]\n",
    "   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "   return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "\n",
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    "\n",
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    return max(candidates, key=NWORDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import all modules needed\n",
    "## lem is lemmatizing the words\n",
    "from nltk.corpus import wordnet\n",
    "def lem(x):\n",
    "    sentence = ''\n",
    "    for x in re.sub('[^a-z0-9 ]','',x).split():   \n",
    "        sentence = sentence + ' ' + lemmatizer.lemmatize(correct(x))\n",
    "    count = 0\n",
    "    return sentence\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "%matplotlib inline\n",
    "from nltk import word_tokenize\n",
    "class LemmaTokenizer(object):\n",
    "     def __init__(self):\n",
    "         self.wnl = WordNetLemmatizer()\n",
    "     def __call__(self, doc):\n",
    "         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10,stop_words=stops,max_features=1000,ngram_range=(1,3),tokenizer=LemmaTokenizer())\n",
    "tfvectorizer = TfidfVectorizer(stop_words=stops,min_df=10,max_features=1000,ngram_range=(1,3),tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take note of the assumptions made in the vectorizer specifications. There are two kinds of vectorizers initialized: count and tfidf. I've limited both to consider only n-grams that appear at least ten times. I've also limited the feature set into the top 1,000 n-grams that appear the most often in the reviews. Also it only extracts unigrams to trigrams. You can edit any of the parameters.\n",
    "\n",
    "### You can switch between count and tfidf vectorizers by changing between \"vectorizer\" and \"tfvectorizer\" in one of the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"C:/Users/kenndanielso/Documents/Github/mcnulty_yelp/data/review_business_df.pkl\", 'rb') as picklefile: \n",
    "    review_business_df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_df = review_business_df.sample(10000,random_state=1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that I've only extract 10,000 sample reviews. This is just to manage its tracktability. Lemmatizing takes a really long time. Indirectly, 10,000 reviews is also big enough relative to the 1,000 features (discussed above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_df = sample_df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_df['spell'] = short_df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_df['s_spell_lem'] = short_df['spell'].apply(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = short_df[['s_spell_lem','stars_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corp = list(new_df.s_spell_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can change the vectorizer type in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = tfvectorizer.fit_transform(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Turns count/tfidf matrix into a dataframe\n",
    "featuredf = pd.DataFrame(feature.A, columns=tfvectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Concat Y and X\n",
    "new_df = pd.concat((new_df,featuredf),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 3002 entries, s_spell_lem to young\n",
      "dtypes: float64(3000), object(2)\n",
      "memory usage: 229.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def string(x):\n",
    "    if x == 5:\n",
    "        return \"five\"\n",
    "    elif x == 4:\n",
    "        return 'four'\n",
    "    elif x == 3:\n",
    "        return 'three'\n",
    "    elif x == 2:\n",
    "        return 'two'\n",
    "    elif x == 1:\n",
    "        return 'one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['stars_x'] = short_df['stars_x'].apply(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_spell_lem</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>100</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ache</th>\n",
       "      <th>across</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would definitely</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i go out to eat often and have been to many p...</td>\n",
       "      <td>four</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always happysatisfied when i leave they have ...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont like fried chicken there i said it sou...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love this little hidden gem best go by far in...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a bit conflict about this cafe because last n...</td>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         s_spell_lem stars_x  100  able  \\\n",
       "0   i go out to eat often and have been to many p...    four  0.0   0.0   \n",
       "1   always happysatisfied when i leave they have ...    five  0.0   0.0   \n",
       "2   i dont like fried chicken there i said it sou...    five  0.0   0.0   \n",
       "3   love this little hidden gem best go by far in...    five  0.0   0.0   \n",
       "4   a bit conflict about this cafe because last n...   three  0.0   0.0   \n",
       "\n",
       "   absolutely  ache    across  actually  add     added  ...    \\\n",
       "0         0.0   0.0  0.126137  0.103447  0.0  0.000000  ...     \n",
       "1         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "2         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "3         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "4         0.0   0.0  0.000000  0.000000  0.0  0.062492  ...     \n",
       "\n",
       "   would definitely  would recommend  wrap  wrong  year  yelp  yes  yet  york  \\\n",
       "0               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "1               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "2               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "3               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "4               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "\n",
       "   young  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('C:/Users/kenndanielso/Documents/Github/mcnulty_yelp/data/kenn_review_df.pkl', 'wb') as picklefile: \n",
    "    pickle.dump(new_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"C:/Users/kenndanielso/Documents/Github/mcnulty_yelp/data/kenn_review_df.pkl\", 'rb') as picklefile: \n",
    "    new_df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapse_df = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Apply this if you want to collapse the 5-star ratings by removing 3-star reviews and combining 1 & 2 stars \n",
    "##and 4 & 5 ratings\n",
    "\n",
    "def collapse(x):\n",
    "    if x == 'four' or x == 'five':\n",
    "        return 'four/five'\n",
    "    elif x == 'one' or x == 'two':\n",
    "        return 'one/two'\n",
    "    elif x == 'three':\n",
    "        return 'three'\n",
    "\n",
    "collapse_df.stars_x = new_df.stars_x.apply(collapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run if you want to delete 3-stars\n",
    "# collapse_df = collapse_df[new_df['stars_x'] != 'three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_spell_lem</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>100</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ache</th>\n",
       "      <th>across</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would definitely</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i go out to eat often and have been to many p...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always happysatisfied when i leave they have ...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont like fried chicken there i said it sou...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love this little hidden gem best go by far in...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a bit conflict about this cafe because last n...</td>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         s_spell_lem    stars_x  100  able  \\\n",
       "0   i go out to eat often and have been to many p...  four/five  0.0   0.0   \n",
       "1   always happysatisfied when i leave they have ...  four/five  0.0   0.0   \n",
       "2   i dont like fried chicken there i said it sou...  four/five  0.0   0.0   \n",
       "3   love this little hidden gem best go by far in...  four/five  0.0   0.0   \n",
       "4   a bit conflict about this cafe because last n...      three  0.0   0.0   \n",
       "\n",
       "   absolutely  ache    across  actually  add     added  ...    \\\n",
       "0         0.0   0.0  0.126137  0.103447  0.0  0.000000  ...     \n",
       "1         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "2         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "3         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "4         0.0   0.0  0.000000  0.000000  0.0  0.062492  ...     \n",
       "\n",
       "   would definitely  would recommend  wrap  wrong  year  yelp  yes  yet  york  \\\n",
       "0               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "1               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "2               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "3               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "4               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "\n",
       "   young  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_spell_lem</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>100</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ache</th>\n",
       "      <th>across</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i go out to eat often and have been to many p...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always happysatisfied when i leave they have ...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont like fried chicken there i said it sou...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love this little hidden gem best go by far in...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.249167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a bit conflict about this cafe because last n...</td>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.279425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         s_spell_lem    stars_x  100  able  \\\n",
       "0   i go out to eat often and have been to many p...  four/five  0.0   0.0   \n",
       "1   always happysatisfied when i leave they have ...  four/five  0.0   0.0   \n",
       "2   i dont like fried chicken there i said it sou...  four/five  0.0   0.0   \n",
       "3   love this little hidden gem best go by far in...  four/five  0.0   0.0   \n",
       "4   a bit conflict about this cafe because last n...      three  0.0   0.0   \n",
       "\n",
       "   absolutely  ache    across  actually  add     added    ...     \\\n",
       "0         0.0   0.0  0.126137  0.103447  0.0  0.000000    ...      \n",
       "1         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "2         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "3         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "4         0.0   0.0  0.000000  0.000000  0.0  0.062492    ...      \n",
       "\n",
       "   would recommend  wrap  wrong  year  yelp  yes  yet  york  young     senti  \n",
       "0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.234848  \n",
       "1              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.578571  \n",
       "2              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.182030  \n",
       "3              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.249167  \n",
       "4              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.279425  \n",
       "\n",
       "[5 rows x 3003 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Adds sentiment as a feature. Note that I added 1 because some algorithms won't accept negative sentiment scores\n",
    "##Sentiment scores is based on TextBlob where it goes from -1.0 to 1.0 (negative to positive)\n",
    "##Change the reference DF if you want to go back to using the 5-star categories\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "collapse_df['senti'] = collapse_df['s_spell_lem'].apply(lambda x: TextBlob(x).sentiment[0] + 1)\n",
    "\n",
    "collapse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split into train and test at 75/25\n",
    "##Change the reference DF if you want to go back to using the 5-star categories\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split X & Y\n",
    "X_train = train.iloc[:,2:]\n",
    "Y_train = train.iloc[:,1]\n",
    "X_test = test.iloc[:,2:]\n",
    "Y_test = test.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy:  0.5644\n",
      "[[ 162  213  107]\n",
      " [  37  204  132]\n",
      " [  66  534 1045]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.81      0.64      0.71      1645\n",
      "    one/two       0.61      0.34      0.43       482\n",
      "      three       0.21      0.55      0.31       373\n",
      "\n",
      "avg / total       0.69      0.56      0.60      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train,Y_train)\n",
    "knn_Y_pred = knn.predict(X_test)\n",
    "print(\"KNN Accuracy: \",np.mean(knn_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,knn_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,knn_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy:  0.7848\n",
      "[[ 345   50   87]\n",
      " [  80  105  188]\n",
      " [  64   69 1512]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.85      0.92      0.88      1645\n",
      "    one/two       0.71      0.72      0.71       482\n",
      "      three       0.47      0.28      0.35       373\n",
      "\n",
      "avg / total       0.76      0.78      0.77      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train,Y_train)\n",
    "nb_Y_pred = nb.predict(X_test)\n",
    "print(\"NB Accuracy: \",np.mean(nb_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,nb_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,nb_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistc Accuracy:  0.792\n",
      "[[ 350   40   92]\n",
      " [  83   75  215]\n",
      " [  43   47 1555]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.84      0.95      0.89      1645\n",
      "    one/two       0.74      0.73      0.73       482\n",
      "      three       0.46      0.20      0.28       373\n",
      "\n",
      "avg / total       0.76      0.79      0.77      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression().fit(X_train,Y_train)\n",
    "log_Y_pred = log.predict(X_test)\n",
    "print(\"Logistc Accuracy: \",np.mean(log_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,log_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,log_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear Accuracy:  0.7824\n",
      "[[ 348   55   79]\n",
      " [  87   86  200]\n",
      " [  53   70 1522]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.85      0.93      0.88      1645\n",
      "    one/two       0.71      0.72      0.72       482\n",
      "      three       0.41      0.23      0.29       373\n",
      "\n",
      "avg / total       0.75      0.78      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Linear SVC\n",
    "from sklearn.svm import SVC\n",
    "svcl = SVC(kernel='linear').fit(X_train,Y_train)\n",
    "svcl_Y_pred = svcl.predict(X_test)\n",
    "print(\"SVC Linear Accuracy: \",np.mean(svcl_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,svcl_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,svcl_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF Accuracy:  0.7404\n",
      "[[ 212    2  268]\n",
      " [  24    0  349]\n",
      " [   6    0 1639]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.73      1.00      0.84      1645\n",
      "    one/two       0.88      0.44      0.59       482\n",
      "      three       0.00      0.00      0.00       373\n",
      "\n",
      "avg / total       0.65      0.74      0.67      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RBF SVC\n",
    "from sklearn.svm import SVC\n",
    "svcrbf = SVC(kernel='rbf', gamma=1).fit(X_train,Y_train)\n",
    "svcrbf_Y_pred = svcrbf.predict(X_test)\n",
    "print(\"SVC RBF Accuracy: \",np.mean(svcrbf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,svcrbf_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,svcrbf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.6716\n",
      "[[ 241  108  133]\n",
      " [  81   99  193]\n",
      " [ 108  198 1339]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.80      0.81      0.81      1645\n",
      "    one/two       0.56      0.50      0.53       482\n",
      "      three       0.24      0.27      0.25       373\n",
      "\n",
      "avg / total       0.67      0.67      0.67      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "dt_Y_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree Accuracy: \",np.mean(dt_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,dt_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,dt_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Accuracy:  0.7544\n",
      "[[ 279   39  164]\n",
      " [  73   44  256]\n",
      " [  43   39 1563]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.79      0.95      0.86      1645\n",
      "    one/two       0.71      0.58      0.64       482\n",
      "      three       0.36      0.12      0.18       373\n",
      "\n",
      "avg / total       0.71      0.75      0.72      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train,Y_train)\n",
    "rf_Y_pred = rf.predict(X_test)\n",
    "print(\"Random Forests Accuracy: \",np.mean(rf_Y_pred == np.array(Y_test)))\n",
    "print(confusion_matrix(Y_test,rf_Y_pred,labels=['one/two','three','four/five']))\n",
    "print(classification_report(Y_test,rf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Modified off-the-shelf sentiment analyzer\n",
    "import nltk.sentiment.util\n",
    "def demo_liu_hu_lexicon2(sentence, plot=False):\n",
    "    print('k')\n",
    "    \"\"\"\n",
    "    Basic example of sentiment classification using Liu and Hu opinion lexicon.\n",
    "    This function simply counts the number of positive, negative and neutral words\n",
    "    in the sentence and classifies it depending on which polarity is more represented.\n",
    "    Words that do not appear in the lexicon are considered as neutral.\n",
    "\n",
    "    :param sentence: a sentence whose polarity has to be classified.\n",
    "    :param plot: if True, plot a visual representation of the sentence polarity.\n",
    "    \"\"\"\n",
    "    from nltk.corpus import opinion_lexicon\n",
    "    from nltk.tokenize import treebank\n",
    "\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    tokenized_sent = [word.lower() for word in tokenizer.tokenize(sentence)]\n",
    "\n",
    "    x = list(range(len(tokenized_sent))) # x axis for the plot\n",
    "    y = []\n",
    "\n",
    "    for word in tokenized_sent:\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words += 1\n",
    "            y.append(1) # positive\n",
    "        elif word in opinion_lexicon.negative():\n",
    "            neg_words += 1\n",
    "            y.append(-1) # negative\n",
    "        else:\n",
    "            y.append(0) # neutral\n",
    "\n",
    "    return (pos_words - neg_words)\n",
    "#     if pos_words > neg_words:\n",
    "#         return 'Positive'\n",
    "#     elif pos_words < neg_words:\n",
    "#         return 'Negative'\n",
    "#     elif pos_words == neg_words:\n",
    "#         return 'Neutral'\n",
    "\n",
    "    if plot == True:\n",
    "        _show_plot(x, y, x_labels=tokenized_sent, y_labels=['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
