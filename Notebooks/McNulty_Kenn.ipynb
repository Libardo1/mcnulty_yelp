{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, collections\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English ##Note you'll need to install Spacy and download its dependencies\n",
    "parser = English()\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom function to clean the text before sending it into the vectorizer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    text = re.sub('[^a-zA-Z ]','',text)\n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(str(TextBlob(sample).correct()))\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3),min_df=3, max_features=1000,tokenizer=tokenizeText)\n",
    "tfvectorizer = TfidfVectorizer(ngram_range=(1,3),min_df = 3,max_features=1000,tokenizer=tokenizeText,sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take note of the assumptions made in the vectorizer specifications. There are two kinds of vectorizers initialized: count and tfidf. I've limited both to consider only n-grams that appear at least ten times. I've also limited the feature set into the top 1,000 n-grams that appear the most often in the reviews. Also it only extracts unigrams to trigrams. You can edit any of the parameters.\n",
    "\n",
    "### You can switch between count and tfidf vectorizers by changing between \"vectorizer\" and \"tfvectorizer\" in one of the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"C:/Users/kennd/Documents/Github/mcnulty_yelp/data/review_business_df.pkl\", 'rb') as picklefile: \n",
    "    review_business_df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_df = review_business_df.sample(10000,random_state=1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that I've only extract 10,000 sample reviews. This is just to manage its tracktability. Lemmatizing takes a really long time. Indirectly, 10,000 reviews is also big enough relative to the 1,000 features (discussed above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_df = sample_df.iloc[:,0:2]\n",
    "short_df.text= short_df.text.apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Gets the count of each word in each sentence\n",
    "countfeature = vectorizer.fit_transform(short_df.text)\n",
    "tffeature = tfvectorizer.fit_transform(short_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Turns count/tfidf matrix into a dataframe\n",
    "countfeaturedf = pd.DataFrame(countfeature.A, columns=vectorizer.get_feature_names())\n",
    "tffeaturedf = pd.DataFrame(tffeature.A, columns=tfvectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Concat Y and X\n",
    "new_df_count = pd.concat((new_df,countfeaturedf),axis=1)\n",
    "new_df_tf = pd.concat((new_df,tffeaturedf),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(new_df_count.info())\n",
    "print(new_df_tf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('C:/Users/kennd/Documents/Github/mcnulty_yelp/data/new_df_count.pkl', 'wb') as picklefile: \n",
    "    pickle.dump(new_df_count, picklefile)\n",
    "import pickle\n",
    "with open('C:/Users/kennd/Documents/Github/mcnulty_yelp/data/new_df_tf.pkl', 'wb') as picklefile: \n",
    "    pickle.dump(new_df_tf, picklefile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def string(x):\n",
    "    if x == 5:\n",
    "        return \"five\"\n",
    "    elif x == 4:\n",
    "        return 'four'\n",
    "    elif x == 3:\n",
    "        return 'three'\n",
    "    elif x == 2:\n",
    "        return 'two'\n",
    "    elif x == 1:\n",
    "        return 'one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['stars_x'] = short_df['stars_x'].apply(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_spell_lem</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>100</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ache</th>\n",
       "      <th>across</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would definitely</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i go out to eat often and have been to many p...</td>\n",
       "      <td>four</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always happysatisfied when i leave they have ...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont like fried chicken there i said it sou...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love this little hidden gem best go by far in...</td>\n",
       "      <td>five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a bit conflict about this cafe because last n...</td>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         s_spell_lem stars_x  100  able  \\\n",
       "0   i go out to eat often and have been to many p...    four  0.0   0.0   \n",
       "1   always happysatisfied when i leave they have ...    five  0.0   0.0   \n",
       "2   i dont like fried chicken there i said it sou...    five  0.0   0.0   \n",
       "3   love this little hidden gem best go by far in...    five  0.0   0.0   \n",
       "4   a bit conflict about this cafe because last n...   three  0.0   0.0   \n",
       "\n",
       "   absolutely  ache    across  actually  add     added  ...    \\\n",
       "0         0.0   0.0  0.126137  0.103447  0.0  0.000000  ...     \n",
       "1         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "2         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "3         0.0   0.0  0.000000  0.000000  0.0  0.000000  ...     \n",
       "4         0.0   0.0  0.000000  0.000000  0.0  0.062492  ...     \n",
       "\n",
       "   would definitely  would recommend  wrap  wrong  year  yelp  yes  yet  york  \\\n",
       "0               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "1               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "2               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "3               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "4               0.0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0   \n",
       "\n",
       "   young  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('C:/Users/kenndanielso/Documents/Github/mcnulty_yelp/data/kenn_review_df.pkl', 'wb') as picklefile: \n",
    "    pickle.dump(new_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"C:/Users/kennd/Documents/GitHub/mcnulty_yelp/data/review_business_df.pkl\", 'rb') as picklefile: \n",
    "    new_df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapse_df = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Apply this if you want to collapse the 5-star ratings by removing 3-star reviews and combining 1 & 2 stars \n",
    "##and 4 & 5 ratings\n",
    "\n",
    "def collapse(x):\n",
    "    if x == 'four' or x == 'five':\n",
    "        return 'four/five'\n",
    "    elif x == 'one' or x == 'two':\n",
    "        return 'one/two'\n",
    "    elif x == 'three':\n",
    "        return 'three'\n",
    "\n",
    "collapse_df.stars_x = new_df.stars_x.apply(collapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run if you want to delete 3-stars\n",
    "# collapse_df = collapse_df[new_df['stars_x'] != 'three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>open</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>PUFPaY9KxDAcGqfsorJp3Q</td>\n",
       "      <td>Ya85v4eqdd6k9Od8HbQjyA</td>\n",
       "      <td>Mr Hoagie</td>\n",
       "      <td>Dravosburg</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.354327</td>\n",
       "      <td>-79.900706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "      <td>None</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Iu6AxdBYGR4A0wspR9BYHA</td>\n",
       "      <td>KPvLNJ21_4wbYNctrOwWdQ</td>\n",
       "      <td>Mr Hoagie</td>\n",
       "      <td>Dravosburg</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.354327</td>\n",
       "      <td>-79.900706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes this place is a little out dated and not o...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>auESFwWvW42h6alXgFxAXQ</td>\n",
       "      <td>fFSoGV46Yxuwbr3fHNuZig</td>\n",
       "      <td>Mr Hoagie</td>\n",
       "      <td>Dravosburg</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.354327</td>\n",
       "      <td>-79.900706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place was DELICIOUS!!  My parents saw a r...</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>LWbYpcangjBMm4KPxZGOKg</td>\n",
       "      <td>6w6gMZ3iBLGcUM4RBIuifQ</td>\n",
       "      <td>Emil's Lounge</td>\n",
       "      <td>rankin</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.413464</td>\n",
       "      <td>-79.880247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can't miss stop for the best Fish Sandwich in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-03-15</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>m1FpV3EAeggaAdfPx0hBRQ</td>\n",
       "      <td>jVVv_DA5mCDB6mediuwHAw</td>\n",
       "      <td>Emil's Lounge</td>\n",
       "      <td>rankin</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>40.413464</td>\n",
       "      <td>-79.880247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text stars_x        date  \\\n",
       "0  Mr Hoagie is an institution. Walking in, it do...    None  2012-08-01   \n",
       "1  Excellent food. Superb customer service. I mis...    None  2014-02-13   \n",
       "2  Yes this place is a little out dated and not o...    None  2015-10-31   \n",
       "3  This place was DELICIOUS!!  My parents saw a r...    None  2012-12-01   \n",
       "4  Can't miss stop for the best Fish Sandwich in ...    None  2013-03-15   \n",
       "\n",
       "              business_id                 user_id               review_id  \\\n",
       "0  5UmKMjUEUNdYWqANhGckJw  PUFPaY9KxDAcGqfsorJp3Q  Ya85v4eqdd6k9Od8HbQjyA   \n",
       "1  5UmKMjUEUNdYWqANhGckJw  Iu6AxdBYGR4A0wspR9BYHA  KPvLNJ21_4wbYNctrOwWdQ   \n",
       "2  5UmKMjUEUNdYWqANhGckJw  auESFwWvW42h6alXgFxAXQ  fFSoGV46Yxuwbr3fHNuZig   \n",
       "3  mVHrayjG3uZ_RLHkLj-AMg  LWbYpcangjBMm4KPxZGOKg  6w6gMZ3iBLGcUM4RBIuifQ   \n",
       "4  mVHrayjG3uZ_RLHkLj-AMg  m1FpV3EAeggaAdfPx0hBRQ  jVVv_DA5mCDB6mediuwHAw   \n",
       "\n",
       "            name        city  open  review_count  stars_y state   latitude  \\\n",
       "0      Mr Hoagie  Dravosburg  True             4      4.5    PA  40.354327   \n",
       "1      Mr Hoagie  Dravosburg  True             4      4.5    PA  40.354327   \n",
       "2      Mr Hoagie  Dravosburg  True             4      4.5    PA  40.354327   \n",
       "3  Emil's Lounge      rankin  True            20      5.0    PA  40.413464   \n",
       "4  Emil's Lounge      rankin  True            20      5.0    PA  40.413464   \n",
       "\n",
       "   longitude  \n",
       "0 -79.900706  \n",
       "1 -79.900706  \n",
       "2 -79.900706  \n",
       "3 -79.880247  \n",
       "4 -79.880247  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_spell_lem</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>100</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ache</th>\n",
       "      <th>across</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i go out to eat often and have been to many p...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>always happysatisfied when i leave they have ...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont like fried chicken there i said it sou...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love this little hidden gem best go by far in...</td>\n",
       "      <td>four/five</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.249167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a bit conflict about this cafe because last n...</td>\n",
       "      <td>three</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.279425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         s_spell_lem    stars_x  100  able  \\\n",
       "0   i go out to eat often and have been to many p...  four/five  0.0   0.0   \n",
       "1   always happysatisfied when i leave they have ...  four/five  0.0   0.0   \n",
       "2   i dont like fried chicken there i said it sou...  four/five  0.0   0.0   \n",
       "3   love this little hidden gem best go by far in...  four/five  0.0   0.0   \n",
       "4   a bit conflict about this cafe because last n...      three  0.0   0.0   \n",
       "\n",
       "   absolutely  ache    across  actually  add     added    ...     \\\n",
       "0         0.0   0.0  0.126137  0.103447  0.0  0.000000    ...      \n",
       "1         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "2         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "3         0.0   0.0  0.000000  0.000000  0.0  0.000000    ...      \n",
       "4         0.0   0.0  0.000000  0.000000  0.0  0.062492    ...      \n",
       "\n",
       "   would recommend  wrap  wrong  year  yelp  yes  yet  york  young     senti  \n",
       "0              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.234848  \n",
       "1              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.578571  \n",
       "2              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.182030  \n",
       "3              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.249167  \n",
       "4              0.0   0.0    0.0   0.0   0.0  0.0  0.0   0.0    0.0  1.279425  \n",
       "\n",
       "[5 rows x 3003 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Adds sentiment as a feature. Note that I added 1 because some algorithms won't accept negative sentiment scores\n",
    "##Sentiment scores is based on TextBlob where it goes from -1.0 to 1.0 (negative to positive)\n",
    "##Change the reference DF if you want to go back to using the 5-star categories\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "collapse_df['senti'] = collapse_df['s_spell_lem'].apply(lambda x: TextBlob(x).sentiment[0] + 1)\n",
    "\n",
    "collapse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split into train and test at 75/25\n",
    "##Change the reference DF if you want to go back to using the 5-star categories\n",
    "from sklearn.cross_validation import train_test_split \n",
    "train, test = train_test_split(collapse_df,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split X & Y\n",
    "X_train = train.iloc[:,2:]\n",
    "Y_train = train.iloc[:,1]\n",
    "X_test = test.iloc[:,2:]\n",
    "Y_test = test.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy:  0.5644\n",
      "[[ 162  213  107]\n",
      " [  37  204  132]\n",
      " [  66  534 1045]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.81      0.64      0.71      1645\n",
      "    one/two       0.61      0.34      0.43       482\n",
      "      three       0.21      0.55      0.31       373\n",
      "\n",
      "avg / total       0.69      0.56      0.60      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train,Y_train)\n",
    "knn_Y_pred = knn.predict(X_test)\n",
    "print(\"KNN Accuracy: \",np.mean(knn_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,knn_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy:  0.7848\n",
      "[[ 345   50   87]\n",
      " [  80  105  188]\n",
      " [  64   69 1512]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.85      0.92      0.88      1645\n",
      "    one/two       0.71      0.72      0.71       482\n",
      "      three       0.47      0.28      0.35       373\n",
      "\n",
      "avg / total       0.76      0.78      0.77      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train,Y_train)\n",
    "nb_Y_pred = nb.predict(X_test)\n",
    "print(\"NB Accuracy: \",np.mean(nb_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,nb_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistc Accuracy:  0.792\n",
      "[[ 350   40   92]\n",
      " [  83   75  215]\n",
      " [  43   47 1555]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.84      0.95      0.89      1645\n",
      "    one/two       0.74      0.73      0.73       482\n",
      "      three       0.46      0.20      0.28       373\n",
      "\n",
      "avg / total       0.76      0.79      0.77      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression().fit(X_train,Y_train)\n",
    "log_Y_pred = log.predict(X_test)\n",
    "print(\"Logistc Accuracy: \",np.mean(log_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,log_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear Accuracy:  0.7824\n",
      "[[ 348   55   79]\n",
      " [  87   86  200]\n",
      " [  53   70 1522]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.85      0.93      0.88      1645\n",
      "    one/two       0.71      0.72      0.72       482\n",
      "      three       0.41      0.23      0.29       373\n",
      "\n",
      "avg / total       0.75      0.78      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Linear SVC\n",
    "from sklearn.svm import SVC\n",
    "svcl = SVC(kernel='linear').fit(X_train,Y_train)\n",
    "svcl_Y_pred = svcl.predict(X_test)\n",
    "print(\"SVC Linear Accuracy: \",np.mean(svcl_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,svcl_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF Accuracy:  0.7404\n",
      "[[ 212    2  268]\n",
      " [  24    0  349]\n",
      " [   6    0 1639]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.73      1.00      0.84      1645\n",
      "    one/two       0.88      0.44      0.59       482\n",
      "      three       0.00      0.00      0.00       373\n",
      "\n",
      "avg / total       0.65      0.74      0.67      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RBF SVC\n",
    "from sklearn.svm import SVC\n",
    "svcrbf = SVC(kernel='rbf', gamma=1).fit(X_train,Y_train)\n",
    "svcrbf_Y_pred = svcrbf.predict(X_test)\n",
    "print(\"SVC RBF Accuracy: \",np.mean(svcrbf_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,svcrbf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.6716\n",
      "[[ 241  108  133]\n",
      " [  81   99  193]\n",
      " [ 108  198 1339]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.80      0.81      0.81      1645\n",
      "    one/two       0.56      0.50      0.53       482\n",
      "      three       0.24      0.27      0.25       373\n",
      "\n",
      "avg / total       0.67      0.67      0.67      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "dt_Y_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree Accuracy: \",np.mean(dt_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,dt_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Accuracy:  0.7544\n",
      "[[ 279   39  164]\n",
      " [  73   44  256]\n",
      " [  43   39 1563]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  four/five       0.79      0.95      0.86      1645\n",
      "    one/two       0.71      0.58      0.64       482\n",
      "      three       0.36      0.12      0.18       373\n",
      "\n",
      "avg / total       0.71      0.75      0.72      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train,Y_train)\n",
    "rf_Y_pred = rf.predict(X_test)\n",
    "print(\"Random Forests Accuracy: \",np.mean(rf_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,rf_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
