{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Import needed modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, collections\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English ##Note you'll need to install Spacy and download its dependencies\n",
    "parser = English()\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A custom function to clean the text before sending it into the vectorizer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    text = re.sub('[^a-zA-Z ]','',text)\n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(str(TextBlob(sample).correct()))\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/kennd/Downloads/testtest.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data and munge munge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[['sentence','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kennd\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2698: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df2.sentence = df2.sentence.apply(cleanText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3),min_df=3, tokenizer=tokenizeText)\n",
    "tfvectorizer = TfidfVectorizer(ngram_range=(1,3),min_df = 3,tokenizer=tokenizeText,sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Gets the count of each word in each sentence\n",
    "countfeature = vectorizer.fit_transform(df2.sentence)\n",
    "tffeature = tfvectorizer.fit_transform(df2.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_count = TruncatedSVD(n_components=50,n_iter=100).fit_transform(countfeature)\n",
    "lsa_tf = TruncatedSVD(n_components=50,n_iter=100).fit_transform(tffeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Transform into word counts into pandas data frame\n",
    "featuredf_count = pd.DataFrame(countfeature.A, columns=vectorizer.get_feature_names())\n",
    "featuredf_tf = pd.DataFrame(tffeature.A, columns=tfvectorizer.get_feature_names())\n",
    "lsa_count_df = pd.DataFrame(lsa_count)\n",
    "lsa_tf_df = pd.DataFrame(lsa_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3_count = pd.concat((df2,featuredf_count),axis=1)\n",
    "df3_tf = pd.concat((df2,featuredf_tf),axis=1)\n",
    "df3_lsa_count = pd.concat((df2,lsa_count_df),axis=1)\n",
    "df3_lsa_tf = pd.concat((df2,lsa_tf_df),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df3_count.info())\n",
    "print(df3_tf.info())\n",
    "print(df3_lsa_count.info())\n",
    "print(df3_lsa_tf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df3_count.to_pickle(\"df3_count\")\n",
    "df3_tf.to_pickle(\"df3_tf\")\n",
    "df3_lsa_count.to_pickle(\"df3_lsa_count\")\n",
    "df3_lsa_tf.to_pickle(\"df3_lsa_tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model and in-training-set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Split into train and test at 75/25\n",
    "train, test = train_test_split(df3_count,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Split X & Y\n",
    "X_train = train.iloc[:,2:]\n",
    "Y_train = train.iloc[:,1]\n",
    "X_test = test.iloc[:,2:]\n",
    "Y_test = test.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KNN Accuracy:  0.463157894737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.17      0.18      0.17        11\n",
      "       food       0.70      0.55      0.62        47\n",
      "     others       0.42      0.38      0.40        26\n",
      "    service       0.27      0.55      0.36        11\n",
      "\n",
      "avg / total       0.51      0.46      0.48        95\n",
      "\n",
      "2 KNN Accuracy:  0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.12      0.27      0.17        11\n",
      "       food       0.61      0.49      0.54        47\n",
      "     others       0.33      0.38      0.36        26\n",
      "    service       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.52      0.40      0.42        95\n",
      "\n",
      "3 KNN Accuracy:  0.526315789474\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.19      0.36      0.25        11\n",
      "       food       0.65      0.79      0.71        47\n",
      "     others       0.47      0.27      0.34        26\n",
      "    service       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.59      0.53      0.51        95\n",
      "\n",
      "4 KNN Accuracy:  0.484210526316\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.11      0.27      0.15        11\n",
      "       food       0.69      0.66      0.67        47\n",
      "     others       0.50      0.35      0.41        26\n",
      "    service       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.58      0.48      0.51        95\n",
      "\n",
      "5 KNN Accuracy:  0.494736842105\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.50      0.09      0.15        11\n",
      "       food       0.56      0.83      0.67        47\n",
      "     others       0.31      0.19      0.24        26\n",
      "    service       0.29      0.18      0.22        11\n",
      "\n",
      "avg / total       0.45      0.49      0.44        95\n",
      "\n",
      "6 KNN Accuracy:  0.505263157895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.12      0.18      0.15        11\n",
      "       food       0.60      0.79      0.68        47\n",
      "     others       0.47      0.27      0.34        26\n",
      "    service       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.55      0.51      0.48        95\n",
      "\n",
      "7 KNN Accuracy:  0.536842105263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.43      0.27      0.33        11\n",
      "       food       0.55      0.89      0.68        47\n",
      "     others       0.50      0.15      0.24        26\n",
      "    service       0.50      0.18      0.27        11\n",
      "\n",
      "avg / total       0.52      0.54      0.47        95\n",
      "\n",
      "8 KNN Accuracy:  0.515789473684\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.20      0.09      0.13        11\n",
      "       food       0.55      0.89      0.68        47\n",
      "     others       0.36      0.15      0.22        26\n",
      "    service       0.67      0.18      0.29        11\n",
      "\n",
      "avg / total       0.47      0.52      0.44        95\n",
      "\n",
      "9 KNN Accuracy:  0.547368421053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       1.00      0.09      0.17        11\n",
      "       food       0.56      0.96      0.70        47\n",
      "     others       0.36      0.15      0.22        26\n",
      "    service       1.00      0.18      0.31        11\n",
      "\n",
      "avg / total       0.61      0.55      0.46        95\n",
      "\n",
      "NB Accuracy:  0.631578947368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.43      0.27      0.33        11\n",
      "       food       0.69      0.91      0.79        47\n",
      "     others       0.56      0.35      0.43        26\n",
      "    service       0.50      0.45      0.48        11\n",
      "\n",
      "avg / total       0.60      0.63      0.60        95\n",
      "\n",
      "SVC Linear Accuracy:  0.631578947368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.50      0.27      0.35        11\n",
      "       food       0.66      0.96      0.78        47\n",
      "     others       0.62      0.31      0.41        26\n",
      "    service       0.50      0.36      0.42        11\n",
      "\n",
      "avg / total       0.61      0.63      0.59        95\n",
      "\n",
      "SVC RBF Accuracy:  0.505263157895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.00      0.00      0.00        11\n",
      "       food       0.51      1.00      0.67        47\n",
      "     others       0.50      0.04      0.07        26\n",
      "    service       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.39      0.51      0.35        95\n",
      "\n",
      "Logistc Accuracy:  0.642105263158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.75      0.27      0.40        11\n",
      "       food       0.62      1.00      0.76        47\n",
      "     others       0.73      0.31      0.43        26\n",
      "    service       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.68      0.64      0.59        95\n",
      "\n",
      "Decision Tree Accuracy:  0.642105263158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.43      0.27      0.33        11\n",
      "       food       0.69      0.89      0.78        47\n",
      "     others       0.58      0.42      0.49        26\n",
      "    service       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.62      0.64      0.62        95\n",
      "\n",
      "Random Forests Accuracy:  0.663157894737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   ambiance       0.75      0.27      0.40        11\n",
      "       food       0.65      0.96      0.78        47\n",
      "     others       0.75      0.46      0.57        26\n",
      "    service       0.50      0.27      0.35        11\n",
      "\n",
      "avg / total       0.67      0.66      0.63        95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kennd\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "##KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for neigh in range(1,10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=neigh).fit(X_train,Y_train)\n",
    "    knn_Y_pred = knn.predict(X_test)\n",
    "    print(neigh,\"KNN Accuracy: \",np.mean(knn_Y_pred == np.array(Y_test)))\n",
    "    print(classification_report(Y_test,knn_Y_pred))\n",
    "\n",
    "## NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train,Y_train)\n",
    "nb_Y_pred = nb.predict(X_test)\n",
    "print(\"NB Accuracy: \",np.mean(nb_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,nb_Y_pred))\n",
    "\n",
    "## Linear SVC\n",
    "from sklearn.svm import SVC\n",
    "svcl = SVC(kernel='linear').fit(X_train,Y_train)\n",
    "svcl_Y_pred = svcl.predict(X_test)\n",
    "print(\"SVC Linear Accuracy: \",np.mean(svcl_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,svcl_Y_pred))\n",
    "\n",
    "## RBF SVC\n",
    "from sklearn.svm import SVC\n",
    "svcrbf = SVC(kernel='rbf', gamma=3).fit(X_train,Y_train)\n",
    "svcrbf_Y_pred = svcrbf.predict(X_test)\n",
    "print(\"SVC RBF Accuracy: \",np.mean(svcrbf_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,svcrbf_Y_pred))\n",
    "\n",
    "## Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression(multi_class='multinomial',solver='newton-cg').fit(X_train,Y_train)\n",
    "log_Y_pred = log.predict(X_test)\n",
    "print(\"Logistc Accuracy: \",np.mean(log_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,log_Y_pred))\n",
    "\n",
    "## Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "dt_Y_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree Accuracy: \",np.mean(dt_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,dt_Y_pred))\n",
    "\n",
    "## Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train,Y_train)\n",
    "rf_Y_pred = rf.predict(X_test)\n",
    "print(\"Random Forests Accuracy: \",np.mean(rf_Y_pred == np.array(Y_test)))\n",
    "print(classification_report(Y_test,rf_Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# food = 1\n",
    "# service = 2\n",
    "# ambiance = 3\n",
    "# others = 4\n",
    "\n",
    "def integerize(x):\n",
    "    if x == 'food':\n",
    "        return 1\n",
    "    elif x == 'service':\n",
    "        return 2\n",
    "    elif x == 'ambiance':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = df3_tf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4.category = df3_count.category.apply(integerize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nn, test_nn = train_test_split(df4,test_size = 0.25)\n",
    "X_train_nn = train_nn.iloc[:,2:].reset_index(drop=True)\n",
    "Y_train_nn = train_nn.iloc[:,1].reset_index(drop=True)\n",
    "X_test_nn = test_nn.iloc[:,2:].reset_index(drop=True)\n",
    "Y_test_nn = test_nn.iloc[:,1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
       "      f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Tanh`: units=200, frozen=False, name='hidden0'>,\n",
       "      layers=[<sknn.nn.Layer `Tanh`: units=200, frozen=False, name='hidden0'>, <sknn.nn.Layer `Softmax`: units=4, frozen=False, name='output'>],\n",
       "      learning_momentum=0.9, learning_rate=0.001, learning_rule='sgd',\n",
       "      loss_type='mcc', n_iter=50, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: units=4, frozen=False, name='output'>,\n",
       "      parameters=None, random_state=None, regularize=None, valid_set=None,\n",
       "      valid_size=0.0, verbose=None, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units=200),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=50,\n",
    "    loss_type='mcc')\n",
    "nn.fit(df4.iloc[:,2:], df4.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(378, 4)]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(df4.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN:  0.551671285798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kennd\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      1.00      0.76       217\n",
      "          2       1.00      0.17      0.30        46\n",
      "          3       0.00      0.00      0.00        39\n",
      "          4       0.85      0.14      0.25        76\n",
      "\n",
      "avg / total       0.64      0.62      0.52       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"NN: \",np.mean(y_pred == np.array(df4.iloc[:,1])))\n",
    "print(classification_report(df4.iloc[:,1],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_text = df2.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_list = tfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_dict = dict.fromkeys(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfvectorizer2 = TfidfVectorizer(ngram_range=(1,3),min_df = 3,tokenizer=tokenizeText,sublinear_tf=True,vocabulary=vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check = tfvectorizer.transform(new_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x208 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
